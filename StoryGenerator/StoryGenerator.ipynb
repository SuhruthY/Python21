{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger, StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the path to java.exe for nltk\n",
    "java_path = \"F:/java/java/bin/java.exe\"\n",
    "    \n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a StanfordPOStagger object\n",
    "pos_base_path = \"E:\\Stanford Taggers\\stanford-postagger-full-2015-04-20\\stanford-postagger-full-2015-04-20\"\n",
    "\n",
    "st_pos = StanfordPOSTagger(model_filename = pos_base_path+\"\\models\\english-bidirectional-distsim.tagger\", path_to_jar = pos_base_path+\"\\stanford-postagger.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a StanfordPOStagger object\n",
    "ner_base_path = \"E:\\Stanford Taggers\\stanford-ner-4.2.0\\stanford-ner-2020-11-17\"\n",
    "    \n",
    "st_ner = StanfordNERTagger(model_filename = ner_base_path+\"\\classifiers\\english.all.3class.distsim.crf.ser.gz\", path_to_jar = ner_base_path+\"\\stanford-ner-4.2.0.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_ner.tag(word_tokenize(\"Hyderabad is my favorate place\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st_pos.tag(word_tokenize(\"Hyderabad is my favorate place\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return a random plot form data frame with Title and Genre\n",
    "def sel_plot(df):\n",
    "    # choosing a random value \n",
    "    num = random.choice([100, 150, 200, 250])\n",
    "    val = random.randrange(1,num)\n",
    "\n",
    "    print(f\"Selected value : {val}\")\n",
    "    \n",
    "    ## re-framing the data\n",
    "    plots = {}\n",
    "    for index,row in df.iterrows():\n",
    "        plots[row[\"Title\"]] = {\"Genre\":row[\"Genre\"], \"Plot\": row[\"Plot\"]}\n",
    "        if index == val: break\n",
    "            \n",
    "    # choosing a random title\n",
    "    titles = list(plots.keys())\n",
    "    sel_movie = random.choice(titles)\n",
    "    \n",
    "    return plots[sel_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to tokenize the plot into Parts of Speech\n",
    "# func to get abb of pos\n",
    "def get_abb(tag_obj):\n",
    "    pos_dct = {}\n",
    "    ner_dct = {}\n",
    "\n",
    "    if type(tag_obj) == str: \n",
    "        pos_tags = st_pos.tag(tag_obj.split())\n",
    "        ner_tags = st_ner.tag(tag_obj.split())\n",
    "    elif type(tag_obj) == list: \n",
    "        pos_tags = st_pos.tag(tag_obj)\n",
    "        ner_tags = st_ner.tag(tag_obj)\n",
    "        \n",
    "    for word,tag in pos_tags:\n",
    "        try:\n",
    "            pos_dct[word] = tag, abb[tag] \n",
    "        except:\n",
    "            pos_dct[word] = tag \n",
    "    for word,tag in ner_tags:\n",
    "        ner_dct[word] = tag\n",
    "\n",
    "        \n",
    "    return {\"Parts of Speech\": pos_dct, \"Named Entities\": ner_dct}\n",
    "\n",
    "# func to get tokens\n",
    "def tokenizer(plot_obj):\n",
    "    plot = plot_obj[\"Plot\"]\n",
    "    get_dct = get_abb(plot)\n",
    "      \n",
    "    return plot_obj[\"Genre\"],get_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer(sel_plot(req_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetching the movie data\n",
    "movies_data = pd.read_csv(\"wiki_movie_plots_deduped.csv\", encoding=\"utf-8\")\n",
    "\n",
    "req_data = movies_data[[\"Title\", \"Genre\", \"Plot\"]]\n",
    "req_data = req_data[req_data[\"Genre\"] != \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the data\n",
    "# cleaning the plot encoding\n",
    "def clean_str(st):\n",
    "    for ch in st :\n",
    "        if ch in '!#$%&\\()*+-/:;<=>@[\\\\]^_`{|}~123456789':\n",
    "            st = st.replace(ch,\"\")\n",
    "    st = st.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    return st\n",
    "\n",
    "req_data[\"Plot\"] = req_data[\"Plot\"].apply(lambda x:clean_str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the required data\n",
    "req_data.to_csv(\"data_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>western</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>comedy</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Dream of a Rarebit Fiend</td>\n",
       "      <td>short</td>\n",
       "      <td>The Rarebit Fiend gorges on Welsh rarebit at a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Title    Genre  \\\n",
       "0           6   The Great Train Robbery  western   \n",
       "1           7           The Suburbanite   comedy   \n",
       "2          10  Dream of a Rarebit Fiend    short   \n",
       "\n",
       "                                                Plot  \n",
       "0  The film opens with two bandits breaking into ...  \n",
       "1  The film is about a family who move to the sub...  \n",
       "2  The Rarebit Fiend gorges on Welsh rarebit at a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the req_data as df\n",
    "req_data = pd.read_csv(\"data_subset.csv\")\n",
    "req_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tags Abrrevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\"\n",
    "res = requests.get(url)\n",
    "soup = bs(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.select(\"table tr\")\n",
    "\n",
    "abb = {}\n",
    "for row in table[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    col_lst = [col.get_text() for col in cols][1:]\n",
    "    abb[col_lst[0].strip()] = col_lst[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the abb dictionary to a csv\n",
    "abb_data = pd.DataFrame.from_dict(abb, orient=\"index\", columns=[\"Full Form\"]).transpose()\n",
    "abb_data.to_csv(\"abbrevations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Form</td>\n",
       "      <td>Coordinating conjunction</td>\n",
       "      <td>Cardinal number</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Existential there</td>\n",
       "      <td>Foreign word</td>\n",
       "      <td>Preposition or subordinating conjunction</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Adjective, comparative</td>\n",
       "      <td>Adjective, superlative</td>\n",
       "      <td>...</td>\n",
       "      <td>Verb, base form</td>\n",
       "      <td>Verb, past tense</td>\n",
       "      <td>Verb, gerund or present participle</td>\n",
       "      <td>Verb, past participle</td>\n",
       "      <td>Verb, non-3rd person singular present</td>\n",
       "      <td>Verb, 3rd person singular present</td>\n",
       "      <td>Wh-determiner</td>\n",
       "      <td>Wh-pronoun</td>\n",
       "      <td>Possessive wh-pronoun</td>\n",
       "      <td>Wh-adverb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                        CC               CD          DT  \\\n",
       "0  Full Form  Coordinating conjunction  Cardinal number  Determiner   \n",
       "\n",
       "                  EX            FW                                        IN  \\\n",
       "0  Existential there  Foreign word  Preposition or subordinating conjunction   \n",
       "\n",
       "          JJ                     JJR                     JJS  ...  \\\n",
       "0  Adjective  Adjective, comparative  Adjective, superlative  ...   \n",
       "\n",
       "                VB               VBD                                 VBG  \\\n",
       "0  Verb, base form  Verb, past tense  Verb, gerund or present participle   \n",
       "\n",
       "                     VBN                                    VBP  \\\n",
       "0  Verb, past participle  Verb, non-3rd person singular present   \n",
       "\n",
       "                                 VBZ            WDT          WP  \\\n",
       "0  Verb, 3rd person singular present  Wh-determiner  Wh-pronoun   \n",
       "\n",
       "                     WP$        WRB  \n",
       "0  Possessive wh-pronoun  Wh-adverb  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading abb_data as df\n",
    "abb_data = pd.read_csv(\"abbrevations.csv\")\n",
    "abb_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StoryGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected value : 85\n"
     ]
    }
   ],
   "source": [
    "res = tokenizer(sel_plot(req_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = res[0]\n",
    "pos_res = res[1][\"Parts of Speech\"]\n",
    "ner_res = res[1][\"Named Entities\"]\n",
    "words = list(pos_res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = random.randrange(5, len(words)//5)\n",
    "pos_choosen = []\n",
    "for i in range(num):\n",
    "    pos_choosen.append(random.choice(words))   \n",
    "    \n",
    "ner_choosen = [wrd for wrd,ner in list(ner_res.items()) if ner != \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More on Verb, non-3rd person singular present at: https://www.google.com/search?q=Verb%2C%20non-3rd%20person%20singular%20present\n",
      "Enter a Verb, non-3rd person singular present:\n",
      "\n",
      "More on PERSON at: https://www.google.com/search?q=PERSON\n",
      "Enter a PERSON:\n",
      "\n",
      "More on Noun, singular or mass at: https://www.google.com/search?q=Noun%2C%20singular%20or%20mass\n",
      "Enter a Noun, singular or mass:\n",
      "\n",
      "More on Adjective at: https://www.google.com/search?q=Adjective\n",
      "Enter a Adjective:\n",
      "\n",
      "More on Verb, 3rd person singular present at: https://www.google.com/search?q=Verb%2C%203rd%20person%20singular%20present\n",
      "Enter a Verb, 3rd person singular present:\n",
      "\n",
      "More on Verb, gerund or present participle at: https://www.google.com/search?q=Verb%2C%20gerund%20or%20present%20participle\n",
      "Enter a Verb, gerund or present participle:\n",
      "\n",
      "More on Personal pronoun at: https://www.google.com/search?q=Personal%20pronoun\n",
      "Enter a Personal pronoun:\n",
      "\n",
      "More on Foreign word at: https://www.google.com/search?q=Foreign%20word\n",
      "Enter a Foreign word:\n",
      "\n",
      "More on Proper noun, singular at: https://www.google.com/search?q=Proper%20noun%2C%20singular\n",
      "Enter a Proper noun, singular:\n",
      "\n",
      "More on Adverb at: https://www.google.com/search?q=Adverb\n",
      "Enter a Adverb:\n",
      "\n",
      "More on Verb, past participle at: https://www.google.com/search?q=Verb%2C%20past%20participle\n",
      "Enter a Verb, past participle:\n",
      "\n",
      "More on Preposition or subordinating conjunction at: https://www.google.com/search?q=Preposition%20or%20subordinating%20conjunction\n",
      "Enter a Preposition or subordinating conjunction:\n",
      "\n",
      "More on Wh-pronoun at: https://www.google.com/search?q=Wh-pronoun\n",
      "Enter a Wh-pronoun:\n",
      "\n",
      "More on Noun, plural at: https://www.google.com/search?q=Noun%2C%20plural\n",
      "Enter a Noun, plural:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Asking user for some words based on their\n",
    "new_words = []\n",
    "occurred = [] \n",
    "for wrd,tup in pos_res.items(): \n",
    "    if tup[1] not in occurred :\n",
    "        if (wrd not in ner_choosen) & (wrd in pos_choosen):  \n",
    "            occurred.append(tup[1])\n",
    "            print (f\"More on {tup[1]} at: https://www.google.com/search?q={quote(tup[1])}\")\n",
    "            new_word = input(f\"Enter a {tup[1]}:\")    \n",
    "            if len(new_word) < 1: new_words.append(wrd)\n",
    "            new_words.append(new_word)\n",
    "            print(\"\")\n",
    "            \n",
    "        elif wrd in ner_choosen:\n",
    "            print (f\"More on {ner_res[wrd]} at: https://www.google.com/search?q={quote(ner_res[wrd])}\")\n",
    "            new_word = input(f\"Enter a {ner_res[wrd]}:\")    \n",
    "            if len(new_word) < 1: new_words.append(wrd)\n",
    "            new_words.append(new_word)\n",
    "            print(\"\")\n",
    "    else:\n",
    "        new_words.append(wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are  Charlie  assistant.  work assistant room. have brief  squabble goes  waiting  room floor carpet sweeper. patient further starts. rear squabbling. dentist arrives, first in, pain. prepares nitrous oxide anaesthesic due unconsciousness. man unconscious he  pulls tooth, can't  him up. calls runs off.  tries eventually  hitting head mallet. revives starts laughing. knocks returns sent  drug store prescription. fighting from  Dr Pain's surgery Sunset Pharmacy. strikes standing newsstand outside. looks woman dentist's wife kicks stomach before chasing himself, incident occurs she loses skirt embarrassment. continues man, who  receives brick face, thus becoming patient. hits passerby equally losing tooth. Meanwhile, gets phone call maid has had \"accident\" home. empty. picks of female other lady leaves, leaving them alone. flirts very closely mouth, stealing kisses. struck by bricks  arrive. girl leaves. tall next. uses huge pair pliers noise victim enters final fight ensues.\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(new_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
